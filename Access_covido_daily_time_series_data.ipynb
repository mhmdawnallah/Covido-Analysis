{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6cf1c45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from datetime import datetime, timedelta\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1452d650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapter Layer\n",
    "\n",
    "def get_data_csvs(url: str, files: list[str]) -> int:\n",
    "    for file in files:\n",
    "        new_url = url%file\n",
    "        print(new_url)\n",
    "        response = requests.get(new_url)\n",
    "        with open(file,'w') as fh:\n",
    "            fh.write(response.text)\n",
    "    \n",
    "    return 0\n",
    "    \n",
    "def get_meta_file(bucket_name,meta_file_name,s3_resource):\n",
    "    download_file_from_s3_bucket(bucket_name,meta_file_name,s3_resource)\n",
    "    return 0\n",
    "\n",
    "def read_csvs_to_df(files: list[str]):\n",
    "    dfs = []\n",
    "    for file in files:\n",
    "        df = pd.read_csv(file)\n",
    "        dfs.append(df)\n",
    "    \n",
    "    return dfs\n",
    "\n",
    "\n",
    "def create_bucket(bucket_name,s3_connection):\n",
    "    session = boto3.session.Session()\n",
    "    current_region = session.region_name\n",
    "    bucket_name = bucket_name\n",
    "    if current_region == 'us-east-1':\n",
    "        bucket_response = s3_connection.create_bucket(\n",
    "            Bucket=bucket_name)\n",
    "    else:\n",
    "        bucket_response = s3_connection.create_bucket(\n",
    "            Bucket=bucket_name,\n",
    "            CreateBucketConfiguration={\n",
    "                'LocationConstraint':current_region\n",
    "            }\n",
    "        )\n",
    "    print(bucket_name,current_region)\n",
    "    return bucket_name, bucket_response\n",
    "\n",
    "def write_csvs_to_s3_bucket(bucket_name,files_names,s3_resource):\n",
    "    for file_name in files_names:\n",
    "        s3_resource.Object(bucket_name, file_name).upload_file(\n",
    "        Filename=file_name)\n",
    "        \n",
    "def download_file_from_s3_bucket(bucket_name,file_name,s3_resource):\n",
    "    s3_resource.Object(bucket_name,file_name).download_file(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0b6760d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Application Layer\n",
    "\n",
    "def extract(url: str, bucket_name: str, meta_file:str,  files: list[str], s3_resource) -> list[pd.DataFrame]:\n",
    "    get_data_csvs(url,files)\n",
    "    get_meta_file(bucket_name,meta_file,s3_resource)\n",
    "    new_files = files.copy()\n",
    "    new_files.append(meta_file)\n",
    "    dfs: list[pd.DataFrame] = read_csvs_to_df(new_files)\n",
    "    return dfs\n",
    "\n",
    "def transform(df_recovered_cases: pd.DataFrame, meta_file: str, source_date: str):\n",
    "    transform_recovered_cases_file(df_recovered_cases)\n",
    "    transfor_meta_file(meta_file,source_date)\n",
    "\n",
    "def load_data(s3_resource, bucket_name: str, files: list[str]) -> int:\n",
    "    first_bucket_name, first_response = create_bucket(\n",
    "    bucket_name= bucket_name,\n",
    "    s3_connection=s3_resource.meta.client)\n",
    "\n",
    "    #Write the data (CSV files) to the bucket\n",
    "    write_csvs_to_s3_bucket(bucket_name,files,s3_resource)\n",
    "    return 0\n",
    "\n",
    "def transform_recovered_cases_file(df_recovered_cases: pd.DataFrame):\n",
    "    #Transform the recovered covid cases\n",
    "    series = df_recovered_cases.iloc[:,4:].max(axis=1).sort_values(ascending=False)\n",
    "    df = df_recovered_cases.merge(series.to_frame('Recovered_Cases'),left_index=True, right_index=True)\n",
    "    df_all_recovered_cases = df[['Province/State','Country/Region','Lat','Long','Recovered_Cases']]\n",
    "    df_all_recovered_cases = df_all_recovered_cases.sort_values(by='Recovered_Cases',ascending=False)\n",
    "    df_recovered_cases.to_csv('time_series_covid19_recovered_global.csv', index=False)\n",
    "    return 0\n",
    "\n",
    "def transfor_meta_file(meta_file_name: str, min_date: str):\n",
    "    curr_date = datetime.now().strftime('%-m/%-d/%-y %-H:%-M:%-S')\n",
    "    df = pd.read_csv(meta_file_name)\n",
    "    print(min_date,curr_date)\n",
    "    row_data = {'source_date':min_date,'processing_date':curr_date}\n",
    "    df2 = pd.DataFrame(row_data,index=[0])\n",
    "    # add df2 to the top of the df\n",
    "    df_meta_file = pd.concat([df2,df])\n",
    "    df_meta_file.to_csv(meta_file_name, index=False)\n",
    "    return 0\n",
    "    \n",
    "\n",
    "def etl_covido_data(url: str, files: list[str], s3_resource, bucket_name: str, meta_file: str) -> int:\n",
    "    df_confirmed_cases, df_deaths_cases, df_recovered_cases, df_meta_file = extract(url,bucket_name,meta_file,files,s3_resource)\n",
    "    \n",
    "    source_date = str(df_confirmed_cases.columns.to_list()[-1])\n",
    "    transform(df_recovered_cases,meta_file,source_date)\n",
    "    \n",
    "    #After editing meta file and saving it to local storage as csv file we append meta_file name to files list \n",
    "    #which further be uploaded to S3 bucket\n",
    "    new_files = files.copy()\n",
    "    new_files.append(meta_file)\n",
    "\n",
    "    #Load the csv files into the S3 Bucket\n",
    "    load_data(s3_resource,bucket_name,new_files)\n",
    "    return df_confirmed_cases, df_deaths_cases, df_recovered_cases, df_meta_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07eb2c42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2eab34d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main function entrypoint\n",
    "\n",
    "def main():\n",
    "    #Parameters/Configurations\n",
    "    url = \"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/%s\"\n",
    "    files = [\n",
    "    \"time_series_covid19_confirmed_global.csv\",\n",
    "    \"time_series_covid19_deaths_global.csv\",\n",
    "    \"time_series_covid19_recovered_global.csv\"\n",
    "]\n",
    "    \n",
    "    # Initialize the S3 resource\n",
    "    s3_resource = boto3.resource('s3')\n",
    "\n",
    "    # Unique global bucket name\n",
    "    bucket_name = 'covido-bucket'\n",
    "\n",
    "    # Meta csv file name for job dates control\n",
    "    meta_file = 'meta_file.csv'\n",
    "    \n",
    "\n",
    "    # ETL the data\n",
    "    result: tuple[pd.DataFrame] = etl_covido_data(url, files, s3_resource, bucket_name, meta_file)\n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3568b9e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv\n",
      "https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv\n",
      "https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_recovered_global.csv\n",
      "6/15/22 6/16/22 7:9:38\n",
      "covido-bucket us-east-1\n"
     ]
    }
   ],
   "source": [
    "# Run the main function\n",
    "df_confirmed_cases, df_deaths_cases, df_recovered_cases, df_meta_file = main() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb54e46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
